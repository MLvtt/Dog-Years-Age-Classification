{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "orig_nbformat": 4,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.2 64-bit ('base': conda)"
    },
    "interpreter": {
      "hash": "f6bdf78043db99d935f40f61a24bf6e40a19bb6491673070e840ece9dc443399"
    },
    "colab": {
      "name": "Copy of model.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLvtt/Dog-Years-Age-Classification/blob/main/Copy_of_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zO9U5rpDhayZ"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.style.use('ggplot')\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3oA_zM8hk6i"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip /content/drive/MyDrive/data/Expert_Train.zip\n",
        "!unzip /content/drive/MyDrive/data/PetFinder_All.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyaIgYdhh_8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f947b52-1e16-4cac-a17b-ff3588aec393"
      },
      "source": [
        "!pip install split_folders\n",
        "import splitfolders\n",
        "splitfolders.ratio('/content/Expert_TrainEval', output='/content/Expert_Split', seed=1337, ratio=(.8, 0.15,0.05))\n",
        "splitfolders.ratio('/content/PetFinder_All', output='/content/PetFinder_Split', seed=1337, ratio=(.8, 0.15,0.05))\n",
        "splitfolders.ratio('/content/Expert_TrainEval', output='/content/Combo_Dataset', seed=1337, ratio=(.8, 0.15,0.05))\n",
        "splitfolders.ratio('/content/PetFinder_All', output='/content/Combo_Dataset', seed=1337, ratio=(.8, 0.15,0.05))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split_folders\n",
            "  Downloading split_folders-0.4.3-py3-none-any.whl (7.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Copying files: 1088 files [00:00, 1501.23 files/s]\n",
            "Copying files: 26190 files [00:09, 2832.14 files/s]\n",
            "Copying files: 1088 files [00:03, 355.97 files/s]\n",
            "Copying files: 26190 files [00:16, 1629.81 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9dBjBuYhayd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d525b43-9922-40f3-f1f9-37c059c0e64c"
      },
      "source": [
        "img_width = 224\n",
        "img_height = 224\n",
        "batch_size = 32\n",
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling (we do not want to modify the testing data)\n",
        "val_datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "\n",
        "# The generator object. \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/Expert_Split/train/',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    '/content/Expert_Split/val/',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 870 images belonging to 3 classes.\n",
            "Found 162 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rFZT77ZkQRc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ccefc73-01cf-4ed3-9aa8-2c75f9256020"
      },
      "source": [
        "data_gen = keras.preprocessing.image.ImageDataGenerator( rescale=1. / 255)\n",
        "data_generator = train_datagen.flow_from_directory('/content/Expert_TrainEval',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1088 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRhRs_C-jyfG"
      },
      "source": [
        "from custom_keras_metrics import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQg2lsEKhaye"
      },
      "source": [
        "IMG_LEN = 224\n",
        "IMG_SHAPE = (IMG_LEN,IMG_LEN,3)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n",
        "base_model.trainable = False\n",
        " \n",
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        " \n",
        "model.compile(optimizer=tf.keras.optimizers.Adamax(0.01),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy', f1_m, precision_m, recall_m])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiQsrQPAkjUu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHBpf2CIkFsF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abeb79e-9e17-4686-e76d-dc17850ad5ef"
      },
      "source": [
        "m = model.fit(train_generator, validation_data=validation_generator, verbose=True, epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "28/28 [==============================] - 41s 1s/step - loss: 1.5009 - accuracy: 0.3782 - f1_m: 0.3617 - precision_m: 0.4004 - recall_m: 0.3337 - val_loss: 1.1569 - val_accuracy: 0.4383 - val_f1_m: 0.4768 - val_precision_m: 0.5401 - val_recall_m: 0.4323\n",
            "Epoch 2/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.9537 - accuracy: 0.5437 - f1_m: 0.4888 - precision_m: 0.5909 - recall_m: 0.4211 - val_loss: 1.1567 - val_accuracy: 0.4383 - val_f1_m: 0.3490 - val_precision_m: 0.3967 - val_recall_m: 0.3125\n",
            "Epoch 3/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.8599 - accuracy: 0.6080 - f1_m: 0.5429 - precision_m: 0.6666 - recall_m: 0.4628 - val_loss: 1.1646 - val_accuracy: 0.4198 - val_f1_m: 0.2740 - val_precision_m: 0.3686 - val_recall_m: 0.2188\n",
            "Epoch 4/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.8653 - accuracy: 0.6103 - f1_m: 0.5838 - precision_m: 0.6744 - recall_m: 0.5182 - val_loss: 1.1677 - val_accuracy: 0.4444 - val_f1_m: 0.3789 - val_precision_m: 0.4458 - val_recall_m: 0.3333\n",
            "Epoch 5/30\n",
            "28/28 [==============================] - 37s 1s/step - loss: 0.7701 - accuracy: 0.6644 - f1_m: 0.6194 - precision_m: 0.7277 - recall_m: 0.5420 - val_loss: 1.2312 - val_accuracy: 0.4444 - val_f1_m: 0.4502 - val_precision_m: 0.4773 - val_recall_m: 0.4271\n",
            "Epoch 6/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.7523 - accuracy: 0.6690 - f1_m: 0.6246 - precision_m: 0.7345 - recall_m: 0.5472 - val_loss: 1.1701 - val_accuracy: 0.4444 - val_f1_m: 0.4116 - val_precision_m: 0.5250 - val_recall_m: 0.3438\n",
            "Epoch 7/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.6903 - accuracy: 0.7161 - f1_m: 0.6817 - precision_m: 0.7923 - recall_m: 0.6008 - val_loss: 1.1936 - val_accuracy: 0.4568 - val_f1_m: 0.3264 - val_precision_m: 0.3629 - val_recall_m: 0.2969\n",
            "Epoch 8/30\n",
            "28/28 [==============================] - 37s 1s/step - loss: 0.6804 - accuracy: 0.7126 - f1_m: 0.6853 - precision_m: 0.7829 - recall_m: 0.6116 - val_loss: 1.2103 - val_accuracy: 0.4074 - val_f1_m: 0.3971 - val_precision_m: 0.4483 - val_recall_m: 0.3594\n",
            "Epoch 9/30\n",
            "28/28 [==============================] - 37s 1s/step - loss: 0.6802 - accuracy: 0.6920 - f1_m: 0.6766 - precision_m: 0.7642 - recall_m: 0.6094 - val_loss: 1.2312 - val_accuracy: 0.4506 - val_f1_m: 0.4664 - val_precision_m: 0.5135 - val_recall_m: 0.4323\n",
            "Epoch 10/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.6591 - accuracy: 0.7287 - f1_m: 0.7091 - precision_m: 0.7974 - recall_m: 0.6406 - val_loss: 1.3679 - val_accuracy: 0.4506 - val_f1_m: 0.4577 - val_precision_m: 0.4803 - val_recall_m: 0.4375\n",
            "Epoch 11/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.6120 - accuracy: 0.7506 - f1_m: 0.7343 - precision_m: 0.8101 - recall_m: 0.6737 - val_loss: 1.2337 - val_accuracy: 0.4691 - val_f1_m: 0.3222 - val_precision_m: 0.3878 - val_recall_m: 0.2760\n",
            "Epoch 12/30\n",
            "28/28 [==============================] - 37s 1s/step - loss: 0.5873 - accuracy: 0.7678 - f1_m: 0.7274 - precision_m: 0.8215 - recall_m: 0.6559 - val_loss: 1.3606 - val_accuracy: 0.4691 - val_f1_m: 0.4820 - val_precision_m: 0.5636 - val_recall_m: 0.4323\n",
            "Epoch 13/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.5970 - accuracy: 0.7529 - f1_m: 0.7453 - precision_m: 0.8187 - recall_m: 0.6856 - val_loss: 1.3257 - val_accuracy: 0.4383 - val_f1_m: 0.4404 - val_precision_m: 0.5389 - val_recall_m: 0.3802\n",
            "Epoch 14/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.5709 - accuracy: 0.7759 - f1_m: 0.7439 - precision_m: 0.8188 - recall_m: 0.6830 - val_loss: 1.3687 - val_accuracy: 0.4383 - val_f1_m: 0.3579 - val_precision_m: 0.3881 - val_recall_m: 0.3333\n",
            "Epoch 15/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.5428 - accuracy: 0.7920 - f1_m: 0.7740 - precision_m: 0.8450 - recall_m: 0.7158 - val_loss: 1.3284 - val_accuracy: 0.4506 - val_f1_m: 0.3355 - val_precision_m: 0.3634 - val_recall_m: 0.3125\n",
            "Epoch 16/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.5133 - accuracy: 0.8230 - f1_m: 0.7963 - precision_m: 0.8713 - recall_m: 0.7359 - val_loss: 1.2855 - val_accuracy: 0.4383 - val_f1_m: 0.4180 - val_precision_m: 0.4531 - val_recall_m: 0.3906\n",
            "Epoch 17/30\n",
            "28/28 [==============================] - 37s 1s/step - loss: 0.5371 - accuracy: 0.7966 - f1_m: 0.7806 - precision_m: 0.8479 - recall_m: 0.7254 - val_loss: 1.3451 - val_accuracy: 0.4506 - val_f1_m: 0.4176 - val_precision_m: 0.4501 - val_recall_m: 0.3906\n",
            "Epoch 18/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.4863 - accuracy: 0.8264 - f1_m: 0.8110 - precision_m: 0.8647 - recall_m: 0.7649 - val_loss: 1.3292 - val_accuracy: 0.4506 - val_f1_m: 0.4316 - val_precision_m: 0.4692 - val_recall_m: 0.4010\n",
            "Epoch 19/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.5033 - accuracy: 0.8310 - f1_m: 0.8169 - precision_m: 0.8819 - recall_m: 0.7630 - val_loss: 1.3499 - val_accuracy: 0.4259 - val_f1_m: 0.4304 - val_precision_m: 0.4595 - val_recall_m: 0.4062\n",
            "Epoch 20/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.4892 - accuracy: 0.8276 - f1_m: 0.8122 - precision_m: 0.8882 - recall_m: 0.7522 - val_loss: 1.3649 - val_accuracy: 0.4444 - val_f1_m: 0.4276 - val_precision_m: 0.4527 - val_recall_m: 0.4062\n",
            "Epoch 21/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.4632 - accuracy: 0.8391 - f1_m: 0.8302 - precision_m: 0.9004 - recall_m: 0.7727 - val_loss: 1.3526 - val_accuracy: 0.4506 - val_f1_m: 0.4238 - val_precision_m: 0.4577 - val_recall_m: 0.3958\n",
            "Epoch 22/30\n",
            "28/28 [==============================] - 37s 1s/step - loss: 0.4606 - accuracy: 0.8529 - f1_m: 0.8450 - precision_m: 0.9071 - recall_m: 0.7920 - val_loss: 1.3932 - val_accuracy: 0.4506 - val_f1_m: 0.4247 - val_precision_m: 0.4528 - val_recall_m: 0.4010\n",
            "Epoch 23/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.4541 - accuracy: 0.8448 - f1_m: 0.8361 - precision_m: 0.8926 - recall_m: 0.7876 - val_loss: 1.3726 - val_accuracy: 0.4259 - val_f1_m: 0.3168 - val_precision_m: 0.3737 - val_recall_m: 0.2760\n",
            "Epoch 24/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.4526 - accuracy: 0.8379 - f1_m: 0.8258 - precision_m: 0.8888 - recall_m: 0.7719 - val_loss: 1.4415 - val_accuracy: 0.4198 - val_f1_m: 0.3318 - val_precision_m: 0.3538 - val_recall_m: 0.3125\n",
            "Epoch 25/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.4372 - accuracy: 0.8529 - f1_m: 0.8277 - precision_m: 0.8725 - recall_m: 0.7891 - val_loss: 1.3807 - val_accuracy: 0.4383 - val_f1_m: 0.4219 - val_precision_m: 0.4618 - val_recall_m: 0.3906\n",
            "Epoch 26/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.4434 - accuracy: 0.8448 - f1_m: 0.8330 - precision_m: 0.8864 - recall_m: 0.7872 - val_loss: 1.4771 - val_accuracy: 0.4321 - val_f1_m: 0.5077 - val_precision_m: 0.5356 - val_recall_m: 0.4844\n",
            "Epoch 27/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.4363 - accuracy: 0.8506 - f1_m: 0.8400 - precision_m: 0.8988 - recall_m: 0.7898 - val_loss: 1.4077 - val_accuracy: 0.4506 - val_f1_m: 0.4433 - val_precision_m: 0.5284 - val_recall_m: 0.3906\n",
            "Epoch 28/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.4106 - accuracy: 0.8701 - f1_m: 0.8633 - precision_m: 0.9103 - recall_m: 0.8222 - val_loss: 1.4583 - val_accuracy: 0.4259 - val_f1_m: 0.4205 - val_precision_m: 0.4500 - val_recall_m: 0.3958\n",
            "Epoch 29/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.4083 - accuracy: 0.8690 - f1_m: 0.8577 - precision_m: 0.8962 - recall_m: 0.8233 - val_loss: 1.4690 - val_accuracy: 0.4074 - val_f1_m: 0.3265 - val_precision_m: 0.3560 - val_recall_m: 0.3021\n",
            "Epoch 30/30\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.4153 - accuracy: 0.8747 - f1_m: 0.8577 - precision_m: 0.9116 - recall_m: 0.8118 - val_loss: 1.5065 - val_accuracy: 0.4321 - val_f1_m: 0.4202 - val_precision_m: 0.4419 - val_recall_m: 0.4010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxAdURRpkLGS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "5cd6192f-e97f-499f-f6a4-c200f039fae8"
      },
      "source": [
        "acc = m.history['accuracy']\n",
        "val_acc = m.history['val_accuracy']\n",
        "f1 = m.history['f1_m']\n",
        "val_f1 = m.history['val_f1_m']\n",
        "prc = m.history['precision_m']\n",
        "val_prc = m.history['val_precision_m']\n",
        "rcl = m.history['recall_m']\n",
        "val_rcl = m.history['val_recall_m']\n",
        "loss = m.history['loss']\n",
        "val_loss = m.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(4, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(4, 1, 1)\n",
        "plt.plot(f1, label='Training F1')\n",
        "plt.plot(val_f1, label='Validation F1')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.title('Training and Validation F1')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "\n",
        "plt.subplot(4, 2, 2)\n",
        "plt.plot(, label='Training F1')\n",
        "plt.plot(val_f1, label='Validation F1')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.title('Training and Validation F1')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "\n",
        "plt.subplot(4, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-bbd08c169645>\"\u001b[0;36m, line \u001b[0;32m30\u001b[0m\n\u001b[0;31m    plt.plot(, label='Training F1')\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yr07nH0BsNFA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}